name: "cifar_vae"
exp_name: "lr0.01_scheduler_noise0.001"

ae:
  model: "latent_ae_cnn_big"
  in_channels: 1
  latent_augmentation: 0.001

data:
  dataset: "cifar_gaussian_200"
  dataset_dir: "/scratch/yufan/nn_diff/gen_param_gen_param/"
#  dataset: "mnist_resnet18"
#  dataset_dir: "/home/yufan/projects/Neural-Network-Diffusion/param_data/mnist"
  augmentation_scale: 0.001

test:
  model: "ConvNet3"
  dataset: "cifar"
  root: "/scratch/datasets/"
  test_bs: 1024

kl_loss_weight: 0.0

train_batch_size: 200
learning_rate: 0.01
scale_lr: False
adam_beta1: 0.9
adam_beta2: 0.999
adam_weight_decay: 2e-6
adam_eps: 1e-8
lr_scheduler: "cosine_with_restarts"
# lr_scheduler: "cosine_with_restarts"
lr_warmup_steps: 0

gradient_accumulation_steps: 1
max_grad_norm: 1.0
num_workers: 4
mixed_precision: "fp16"

num_training_steps: 30000
validation_steps: 20
seed: 3407
